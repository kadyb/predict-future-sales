---
title: "<center> **Predict Future Sales** <center>"
author: "<center> **Krzysztof Dyba** </center>"
date: "<center> `r Sys.Date()` </center>"
output:
  html_document: 
    toc: true
    toc_float: true
    highlight: tango
    theme: spacelab
    df_print: kable
---

<style>
body {text-align: justify}
</style>

# Introduction

The goal of this project is to predict the total amount of products sold in every shop in the future. Time-series dataset containing historical daily sales data was provided by **1C Company**, which is one of the largest Russian software firms.

## Files description
The following files were provided:

1. **sales_train.csv** - the training set. Daily historical data from January 2013 to October 2015:
    + **date** - date in format dd/mm/yyyy,
    + **date_block_num** - a consecutive month number (January 2013 is 0, October 2015 is 33),
    + **shop_id** - unique identifier of a shop,
    + **item_id** - unique identifier of a product,
    + **item_price** - current price of an item,
    + **item_cnt_day** - number of products sold,
2. **items.csv** - supplemental information about the items/products:
    + **item_name** - name of item,
    + **item_id** - unique identifier of a product,
    + **item_category_id** - unique identifier of item category,
3. **item_categories.csv** - supplemental information about the items categories:
    + **item_category_id** - unique identifier of item category,
    + **item_category_name** - name of item category,
4. **shops.csv** - supplemental information about the shops:
    + **shop_id** - unique identifier of a shop,
    + **shop_name** - name of shop.

```{r include = FALSE}
startTime = Sys.time()
```

# Load libraries

```{r message = FALSE}
library("ggplot2")
library("cowplot")
library("data.table")
```

# Load data

```{r message = FALSE}
sales = fread("data/sales_train_v2.csv", showProgress = FALSE)
items = fread("data/items.csv", encoding = "UTF-8")
shops = fread("data/shops.csv", encoding = "UTF-8")
itemCat = fread("data/item_categories.csv", encoding = "UTF-8")
```

The **fread** function is used to read data, which is about 10 times faster than the standard **read.csv** function. In addition, it uses less memory and other functions are optimized for processing big data.

## Data conversion

```{r}
sales[, date := as.IDate(as.Date(date, format = "%d.%m.%Y"))]
```

Convert the date to the correct format (**"%Y-%m-%d"**) and type.

```{r}
sales = merge(sales, items, by = "item_id")
```

Merge items dataset with sales by **"item_id"** column.

```{r}
factorCols = c("item_id", "shop_id", "item_category_id")
sales[, (factorCols) := lapply(.SD, factor), .SDcols = factorCols]
```

Convert selected variables to factor data type.

# Exploratory data analysis

## First look {.tabset .tabset-fade}

### Dimension

```{r}
dim(sales)
```

The analyzed dataset consists of **2 935 849** rows and **8** columns.

### Groups count
```{r collapse = TRUE}
paste0("Shops: ", length(levels(sales[, shop_id])))
paste0("Items: ", length(levels(sales[, item_id])))
paste0("Items categories: ", length(levels(sales[, item_category_id])))
```

Sales data come from 60 stores, which sold 21 807 different items grouped into 84 categories.

### Missing data

```{r}
# The fastest way from tested to check NA in columns
apply(sapply(sales, is.na), 2, function(x) any(x))
```

There were no missing values in this dataset.

### Duplicates

```{r}
sales[duplicated(sales), ]
```

Only 6 duplicates were found, but none appear to be incorrect. They relate to the sale of computer games and movies.

### Sales

```{r}
shop_id_grouped = sales[, .N, by = .(shop_id)]

ggplot(shop_id_grouped, aes(x = reorder(shop_id, N), y = N)) +
  geom_col() +
  labs(title = "Total sales by stores") +
  xlab("Shop ID") +
  ylab("Sales") +
  coord_flip() +
  theme_light()
```

Based on the chart, we can notice a strong unbalance in stores sales. The 5 stores with the largest total number of sales are located respectively in Moscow, Moscow, Khimki, Moscow and Saint Petersburg. However, the worst results are recorded in stores in Novosibirsk, Zhukovsky and astonishingly in Moscow.

```{r}
ggplot(sales, aes(x = date_block_num)) +
  geom_bar() +
  geom_vline(xintercept = 11.5) +
  geom_vline(xintercept = 23.5) +
  annotate("text", x = 1.5, y = 150000, label = "2013") +
  annotate("text", x = 13.5, y = 150000, label = "2014") +
  annotate("text", x = 25.5, y = 150000, label = "2015") +
  labs(title = "Unique sales by month") +
  xlab("Month") +
  ylab("Sales") +
  theme_light()
```

The two months with the largest number of unique sales are December 2014 and 2015. There is a downward trend over the months.

### Outliers

```{r fig.height = 2, fig.width = 7}
p1 = ggplot(sales, aes(y = item_price)) +
  geom_boxplot() +
  scale_y_continuous(breaks = c(0, 100000, 200000, 300000),
                     labels = c("0", "100000", "200000", "300000")) +
  labs(title = "Prices of all products") +
  ylab("Price") +
  coord_flip() +
  theme_light() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

p2 = ggplot(sales, aes(y = item_cnt_day)) +
  geom_boxplot() +
  scale_y_continuous(breaks = c(0, 500, 1000, 1500, 2000),
                     labels = c("0", "500", "1000", "1500", "2000")) +
  labs(title = "Daily sold products") +
  ylab("Sold products") +
  coord_flip() +
  theme_light() +
  theme_light() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

# Function "plot_grid" is faster than "grid.arrange" (about 15 s)
plot_grid(p1, p2)
```

There are many outliers that need to be carefully analyzed and then correct or delete them.

**Prices of all products**

```{r}
head(sales[order(-item_price), ], 6)
```

The first item sold for 307 980 rubles is a remote control software sold in one transaction to 522 people, which results in such a high price. The original value was divided by 522.

The second outlier is the delivery service for a private online store. Comparing this value with the median price of this service (`r median(sales[item_id == 11365, item_price])`), it appears to be incorrect. This row has been removed from dataset.

```{r}
sales[item_price == 307980, item_price := 307980/522]
sales = sales[!(item_id == 11365 & item_price == 59200)]
```

The next values seem to be valid. They concern i.a. collector's edition of chess, specialized software or limited edition of consoles.

```{r}
sales[item_price == -1]
```

One negative value appears, which is probably also an error. The median value of other products with this ID is `r median(sales[item_id == 2973, item_price])`. This row has been removed.

```{r}
sales = sales[!(item_id == 2973 & item_price == -1)]
```

**Daily sold products**

```{r}
head(sales[order(-item_cnt_day), ], 5)
```

The largest number of transactions concerns the delivery service to the destination point. However, it is also probably incorrect. The cost of the service is significantly underestimated compared to others. This is well illustrated in the figure below.

```{r fig.height = 3, fig.width = 6}
cnt_df = data.frame(price = sales[item_id == 11373, item_price],
                    amount = sales[item_id == 11373, item_cnt_day])

ggplot(cnt_df, aes(x = price, y = amount, size = amount/price)) +
  geom_point(show.legend = FALSE) +
  labs(title = "Delivery service") +
  xlab("Amount") +
  ylab("Price") +
  theme_light()
```

```{r}
sales = sales[!(item_id == 11373 & item_cnt_day == 2169)]
```

The outlier mentioned above has been removed.

```{r}
head(sales[order(item_cnt_day), ], 5)
```

Negative values appear in the **"item_cnt_day"** column, which probably means product returns. In total, `r length(sales[item_cnt_day < 0, item_cnt_day])` returns were made and `r abs(sum(sales[item_cnt_day < 0, item_cnt_day]))` products were returned. These values have been preserved unchanged.

### Shop names

```{r}
shops[c(1, 2, 58, 59), 1]
```

These two locations in Yakutsk probably mean the same stores, although they have different IDs.

```{r}
shops[c(11, 12), 1]
```

A similar situation is in Zhukovsky. Store names differ only by one character ("?" instead of "2").

## Data mining

# Feature engineer

1. Extract month and year from date to separate variables.

```{r}
sales[, month := as.factor(month(sales$date))]
sales[, year := as.factor(year(sales$date))]
```


2. Create a variable with the names of the places where the stores are located.

```{r}
shopLoc = c("Yakutsk", "Yakutsk", "Adygea", "Balashikha", "Volzhsky", "Vologda",
            "Voronezh", "Voronezh", "Voronezh", "Outbound trade", "Zhukovsky",
            "Zhukovsky", "Online store private", "Kazan", "Kazan", "Kaluga", "Kolomna",
            "Krasnoyarsk", "Krasnoyarsk", "Kursk", "Moscow", "Moscow", "Moscow",
            "Moscow", "Moscow", "Moscow", "Moscow", "Moscow", "Moscow",
            "Moscow", "Moscow", "Moscow", "Moscow", "Mytishchi", "Nizhny Novgorod",
            "Nizhny Novgorod", "Novosibirsk", "Novosibirsk", "Omsk", "Rostov-on-Don",
            "Rostov-on-Don", "Rostov-on-Don", "Saint Petersburg", "Saint Petersburg",
            "Samara", "Samara", "Sergiyev Posad", "Surgut", "Tomsk", "Tyumen",
            "Tyumen", "Tyumen", "Ufa", "Ufa", "Khimki", "Online store 1C", 
            "Chekhov", "Yakutsk", "Yakutsk", "Yaroslavl")
shopLoc = factor(shopLoc)
shopLabels = as.numeric(shopLoc)
```

3. Extract the main and secondary category names from the category description.

```{r}
catNames = c("mainCategory", "subCategory")
itemCat[, (catNames) := tstrsplit(item_category_name, " - ", 
                                  type.convert = TRUE, fixed = TRUE)]
itemCat[is.na(subCategory), subCategory := mainCategory]
```


# Summary

# TODO
1. kiedy produkt pojawil sie na rynku (miesiac jako num block)
2. ile czasu produkt byl na rynku (dni)
3. ile razy przedmiot byl zwracany (albo czy byl w ogole zwracany)
3. dodac sredni kurs miesieczny rubel-dolar
4. dodac swieta panstwowe w rosji (https://www.timeanddate.com/calendar/)
5. liczba dni targowych (http://fs.moex.com/files/3791/)
6. pamietac zeby przyciac wartosci do zakresu 0-20 (wieksza niz 20 staja sie 20)

1. wyznaczyc kategorie przedmiotow na podstawie podobienstwa ich nazw (biblioteka "stringdist")

1. ensemble modeling,
2. lstm,
3. hierarchical time series


---

<center> <font size = "2"> <i>
The code was executed in `r round(difftime(Sys.time(), startTime, units = "mins"))` min.
<center> </font> </i>